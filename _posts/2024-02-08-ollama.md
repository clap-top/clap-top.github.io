---
title: '搭建自己的AI助手-ollama部署指南'
date: 2024-02-08 08:00:00
permalink: /posts/2024/02/ollama/
excerpt: ollama 可以帮助你在本地启动并运行大型语言模型，来搭建专属于你自己的 AI 助手。
tags:
  - tools
  - AI
redirect_from:
  - ollama
---

## 介绍

ollama 可以帮助你在本地启动并运行大型语言模型，来搭建专属于你自己的 AI 助手。

| Model              | Parameters | Size  | Download                       |
| ------------------ | ---------- | ----- | ------------------------------ |
| Llama 2            | 7B         | 3.8GB | `ollama run llama2`            |
| Mistral            | 7B         | 4.1GB | `ollama run mistral`           |
| Dolphin Phi        | 2.7B       | 1.6GB | `ollama run dolphin-phi`       |
| Phi-2              | 2.7B       | 1.7GB | `ollama run phi`               |
| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`       |
| Starling           | 7B         | 4.1GB | `ollama run starling-lm`       |
| Code Llama         | 7B         | 3.8GB | `ollama run codellama`         |
| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored` |
| Llama 2 13B        | 13B        | 7.3GB | `ollama run llama2:13b`        |
| Llama 2 70B        | 70B        | 39GB  | `ollama run llama2:70b`        |
| Orca Mini          | 3B         | 1.9GB | `ollama run orca-mini`         |
| Vicuna             | 7B         | 3.8GB | `ollama run vicuna`            |
| LLaVA              | 7B         | 4.5GB | `ollama run llava`             |

> 注意：运行 7B 需要至少 8 GB 可用 RAM，13B 需要至少 16 GB 来运行 RAM，33B 需要至少 32 GB 来运行 RAM。

## 准备环境

- macOS / Linux & 至少 8GB 的 RAM
- Docker [Docker 安装指南](https://selfhost.vip/ghost/docker)

> 目前暂不支持 Windows 直接安装

## 部署 Ollama

### 安装

> 📢：Ollama 默认会占用 11434 端口

#### macOS

从 [下载链接](https://ollama.ai/download/Ollama-darwin.zip) 下载安装即可

#### Linux

```bash
curl https://ollama.ai/install.sh | sh
```

#### Docker

```bash
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

### 下载模型文件

这里 [Link](https://ollama.ai/library) 有可以使用的模型文件，你可以看下介绍，然后根据自己的电脑配置及需要下载不同的模型文件即可。
如下图所示，我是选择了 tinyllama 的模型文件。对于每个模型文件还有区分不同参数数量的模型细项，后面有对应的安装指令。
这里我选择使用 tinyllama 默认的选项，所以执行的如下命令。

```bash
ollama run tinyllama
```

![](https://i.imgur.com/9f88DBM.png)

安装完成后，会出现如下的提示：
![](https://i.imgur.com/oZig9bg.png)  
此时在这里收入你的指令即可以使用了。如下所示（_因为的电脑性能还可以，所以响应速度还不错_）：

![](https://i.imgur.com/Lcsevk2.gif)

### Web 界面安装 [chatbot ui](https://github.com/ivanfioravanti/chatbot-ollama)

考虑到通过终端使用的不便利性，所以我们可以通过安装 chatbot ui 来使用我们的 AI。

效果如下图所示  
![](https://i.imgur.com/T4KAtBw.png)

#### 安装步骤

##### 1. 确保已安装好 Docker，如果没有安装可以参考 [Docker 安装指南](https://selfhost.vip/ghost/docker)

##### 2. 安装 Chatbot-ui

在终端执行如下命令即可，会占用电脑的 3000 端口，也可以通过修改“:”前的 3000 修改为其他的端口。

```bash
docker run -p 3000:3000 ghcr.io/ivanfioravanti/chatbot-ollama:main
```

到出现如下内容，即可打开浏览器并输入<http://127.0.0.1:3000>使用了。
![](https://i.imgur.com/wo3HOVQ.png)  
效果如下：
![](https://i.imgur.com/jOH2efe.gif)
